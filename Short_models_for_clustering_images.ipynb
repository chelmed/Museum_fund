{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import gc\n",
    "import random\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "import efficientnet.tfkeras as ef\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array\n",
    "import tensorflow.keras.models as M\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow.keras.layers as L\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas version:  1.2.2\n",
      "numpy version:  1.19.5\n",
      "sklearn version:  0.23.2\n",
      "matplotlib version:  3.3.2\n",
      "tensorflow version:  2.4.1\n",
      "efficientnet version: 1.1.1\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import sklearn\n",
    "print(\"pandas version: \", pd.__version__)\n",
    "print(\"numpy version: \", np.__version__)\n",
    "print(\"sklearn version: \", sklearn.__version__)\n",
    "print(\"matplotlib version: \", matplotlib.__version__)\n",
    "print(\"tensorflow version: \", tf.__version__)\n",
    "print(\"efficientnet version: 1.1.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### подробнее про библиотеку efficientnet: https://pypi.org/project/keras-efficientnets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true' #gpu\n",
    "#Whether or not to load truncated image files\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "#Image size exceeds not limit\n",
    "Image.MAX_IMAGE_PIXELS = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=42    \n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# кастомная функция для f1\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Фильтрую дф по наличию изображения в каталоге"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_images = list()\n",
    "for filename in os.listdir(\"images\"):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        list_images.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv') \n",
    "train['image_id']  = train['guid'] + '.jpg'\n",
    "train['have_image'] = train['image_id'].apply(lambda x: 1 if x in list_images else 0)\n",
    "train = train.query(\"have_image==1\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 512\n",
    "input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "batch_size = 8\n",
    "num_epochs = 30\n",
    "LR = 0.00007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./(IMG_SIZE - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datagen(df):\n",
    "    return datagen.flow_from_dataframe(\n",
    "        dataframe=df,\n",
    "        directory=\"images\",\n",
    "        x_col=\"image_id\",\n",
    "        y_col=\"typology\",\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        #validation_split=0.15,\n",
    "        shuffle=True, \n",
    "        seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружу общедоступные предобученные веса на Imagenet на архитектуре EfficientNetB6, на основе этой архитерктуры достроим нейронную сеть подробнее про архитектуру https://paperswithcode.com/paper/fixing-the-train-test-resolution-discrepancy-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_model = efn.EfficientNetB6(weights=\"imagenet\", include_top=False, input_shape=input_shape)\n",
    "#base_model.save(\"EfficientNetB6.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def architecture_NN():\n",
    "    inp = L.Input(shape=input_shape)\n",
    "    base_model = efn.EfficientNetB6(weights=\"EfficientNetB6.h5\", include_top=False, input_shape=input_shape)\n",
    "    base_model.trainable = False\n",
    "    x = base_model(inp)\n",
    "    x = L.GlobalAveragePooling2D()(x)\n",
    "    bn = L.Dense(50, activation = 'relu', kernel_initializer='he_uniform')(x)\n",
    "    out = L.Dense(15, activation = 'softmax', kernel_initializer='glorot_uniform')(bn)\n",
    "    model = tf.keras.models.Model(inputs = inp, outputs = out)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_22 (InputLayer)        [(None, 512, 512, 3)]     0         \n",
      "_________________________________________________________________\n",
      "efficientnet-b6 (Functional) (None, 16, 16, 2304)      40960136  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_5 ( (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 300)               691500    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 15)                4515      \n",
      "=================================================================\n",
      "Total params: 41,656,151\n",
      "Trainable params: 696,015\n",
      "Non-trainable params: 40,960,136\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "architecture_NN().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "время обучения на 3060 около 3 часов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3804 validated image filenames belonging to 15 classes.\n",
      "Found 544 validated image filenames belonging to 15 classes.\n",
      "Epoch 1/70\n",
      "476/476 [==============================] - 234s 463ms/step - loss: 2.0005 - f1_m: 0.1998 - val_loss: 1.2638 - val_f1_m: 0.5329\n",
      "Epoch 2/70\n",
      "476/476 [==============================] - 216s 454ms/step - loss: 1.1725 - f1_m: 0.5930 - val_loss: 1.0187 - val_f1_m: 0.6468\n",
      "Epoch 3/70\n",
      "476/476 [==============================] - 212s 445ms/step - loss: 0.9337 - f1_m: 0.6643 - val_loss: 0.9916 - val_f1_m: 0.6521\n",
      "Epoch 4/70\n",
      "476/476 [==============================] - 220s 461ms/step - loss: 0.7500 - f1_m: 0.7439 - val_loss: 1.0011 - val_f1_m: 0.6722\n",
      "Epoch 5/70\n",
      "476/476 [==============================] - 215s 451ms/step - loss: 0.6289 - f1_m: 0.7896 - val_loss: 1.0178 - val_f1_m: 0.6771\n",
      "Epoch 6/70\n",
      "476/476 [==============================] - 215s 451ms/step - loss: 0.4703 - f1_m: 0.8387 - val_loss: 1.1294 - val_f1_m: 0.6635\n",
      "Epoch 7/70\n",
      "476/476 [==============================] - 226s 474ms/step - loss: 0.3765 - f1_m: 0.8731 - val_loss: 1.0873 - val_f1_m: 0.6702\n",
      "Epoch 8/70\n",
      "476/476 [==============================] - 226s 475ms/step - loss: 0.3147 - f1_m: 0.8941 - val_loss: 1.2063 - val_f1_m: 0.6885\n",
      "Epoch 9/70\n",
      "476/476 [==============================] - 223s 468ms/step - loss: 0.2487 - f1_m: 0.9188 - val_loss: 1.2093 - val_f1_m: 0.6588\n",
      "Epoch 10/70\n",
      "476/476 [==============================] - 229s 482ms/step - loss: 0.2009 - f1_m: 0.9332 - val_loss: 1.2721 - val_f1_m: 0.6811\n",
      "Epoch 11/70\n",
      "476/476 [==============================] - 230s 483ms/step - loss: 0.1730 - f1_m: 0.9425 - val_loss: 1.3471 - val_f1_m: 0.6878\n",
      "Epoch 12/70\n",
      "476/476 [==============================] - 212s 445ms/step - loss: 0.1584 - f1_m: 0.9437 - val_loss: 1.4587 - val_f1_m: 0.6792\n",
      "Epoch 13/70\n",
      "476/476 [==============================] - 217s 455ms/step - loss: 0.1500 - f1_m: 0.9549 - val_loss: 1.4150 - val_f1_m: 0.6739\n",
      "Epoch 14/70\n",
      "476/476 [==============================] - 210s 441ms/step - loss: 0.1068 - f1_m: 0.9651 - val_loss: 1.4023 - val_f1_m: 0.6971\n",
      "Epoch 15/70\n",
      "476/476 [==============================] - 211s 443ms/step - loss: 0.1277 - f1_m: 0.9616 - val_loss: 1.5687 - val_f1_m: 0.6673\n",
      "Epoch 16/70\n",
      "476/476 [==============================] - 211s 442ms/step - loss: 0.1012 - f1_m: 0.9655 - val_loss: 1.5215 - val_f1_m: 0.6827\n",
      "Epoch 17/70\n",
      "476/476 [==============================] - 211s 442ms/step - loss: 0.1126 - f1_m: 0.9681 - val_loss: 1.5138 - val_f1_m: 0.6748\n",
      "Epoch 18/70\n",
      "476/476 [==============================] - 210s 440ms/step - loss: 0.0791 - f1_m: 0.9779 - val_loss: 1.5228 - val_f1_m: 0.6985\n",
      "Epoch 19/70\n",
      "476/476 [==============================] - 211s 443ms/step - loss: 0.0940 - f1_m: 0.9662 - val_loss: 1.5893 - val_f1_m: 0.7038\n",
      "Epoch 20/70\n",
      "476/476 [==============================] - 210s 441ms/step - loss: 0.0756 - f1_m: 0.9811 - val_loss: 1.4914 - val_f1_m: 0.7095\n",
      "Epoch 21/70\n",
      "476/476 [==============================] - 210s 442ms/step - loss: 0.0784 - f1_m: 0.9721 - val_loss: 1.5286 - val_f1_m: 0.6973\n",
      "Epoch 22/70\n",
      "476/476 [==============================] - 211s 442ms/step - loss: 0.0610 - f1_m: 0.9817 - val_loss: 1.6414 - val_f1_m: 0.6866\n",
      "Epoch 23/70\n",
      "476/476 [==============================] - 211s 443ms/step - loss: 0.0748 - f1_m: 0.9792 - val_loss: 1.6451 - val_f1_m: 0.6973\n",
      "Epoch 24/70\n",
      "476/476 [==============================] - 210s 441ms/step - loss: 0.0915 - f1_m: 0.9701 - val_loss: 1.6440 - val_f1_m: 0.6994\n",
      "Epoch 25/70\n",
      "476/476 [==============================] - 210s 441ms/step - loss: 0.0696 - f1_m: 0.9812 - val_loss: 1.6911 - val_f1_m: 0.7009\n",
      "Epoch 26/70\n",
      "476/476 [==============================] - 210s 441ms/step - loss: 0.0598 - f1_m: 0.9811 - val_loss: 1.6062 - val_f1_m: 0.7003\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00026: early stopping\n",
      "Found 3804 validated image filenames belonging to 15 classes.\n",
      "Found 544 validated image filenames belonging to 15 classes.\n",
      "Epoch 1/70\n",
      "476/476 [==============================] - 222s 445ms/step - loss: 2.0029 - f1_m: 0.2215 - val_loss: 1.2515 - val_f1_m: 0.5280\n",
      "Epoch 2/70\n",
      "476/476 [==============================] - 211s 442ms/step - loss: 1.1840 - f1_m: 0.5634 - val_loss: 1.0627 - val_f1_m: 0.6242\n",
      "Epoch 3/70\n",
      "476/476 [==============================] - 210s 440ms/step - loss: 0.9160 - f1_m: 0.6822 - val_loss: 1.0403 - val_f1_m: 0.6304\n",
      "Epoch 4/70\n",
      "476/476 [==============================] - 210s 442ms/step - loss: 0.7199 - f1_m: 0.7454 - val_loss: 1.0245 - val_f1_m: 0.6659\n",
      "Epoch 5/70\n",
      "476/476 [==============================] - 210s 441ms/step - loss: 0.6137 - f1_m: 0.7928 - val_loss: 1.0035 - val_f1_m: 0.6846\n",
      "Epoch 6/70\n",
      "476/476 [==============================] - 210s 441ms/step - loss: 0.4789 - f1_m: 0.8422 - val_loss: 1.0412 - val_f1_m: 0.6815\n",
      "Epoch 7/70\n",
      "476/476 [==============================] - 210s 441ms/step - loss: 0.3798 - f1_m: 0.8784 - val_loss: 1.1406 - val_f1_m: 0.6751\n",
      "Epoch 8/70\n",
      "476/476 [==============================] - 210s 442ms/step - loss: 0.3319 - f1_m: 0.8883 - val_loss: 1.1640 - val_f1_m: 0.6821\n",
      "Epoch 9/70\n",
      "476/476 [==============================] - 209s 440ms/step - loss: 0.2263 - f1_m: 0.9228 - val_loss: 1.2157 - val_f1_m: 0.6792\n",
      "Epoch 10/70\n",
      "476/476 [==============================] - 210s 440ms/step - loss: 0.1974 - f1_m: 0.9319 - val_loss: 1.3172 - val_f1_m: 0.6778\n",
      "Epoch 11/70\n",
      "476/476 [==============================] - 210s 441ms/step - loss: 0.1940 - f1_m: 0.9362 - val_loss: 1.3767 - val_f1_m: 0.6829\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Found 3804 validated image filenames belonging to 15 classes.\n",
      "Found 544 validated image filenames belonging to 15 classes.\n",
      "Epoch 1/70\n",
      "476/476 [==============================] - 222s 447ms/step - loss: 2.0229 - f1_m: 0.2047 - val_loss: 1.2148 - val_f1_m: 0.5864\n",
      "Epoch 2/70\n",
      "476/476 [==============================] - 210s 442ms/step - loss: 1.1868 - f1_m: 0.5843 - val_loss: 1.0371 - val_f1_m: 0.6383\n",
      "Epoch 3/70\n",
      "476/476 [==============================] - 211s 443ms/step - loss: 0.8803 - f1_m: 0.7050 - val_loss: 0.9905 - val_f1_m: 0.6422\n",
      "Epoch 4/70\n",
      "476/476 [==============================] - 210s 442ms/step - loss: 0.7732 - f1_m: 0.7312 - val_loss: 0.9692 - val_f1_m: 0.6952\n",
      "Epoch 5/70\n",
      "476/476 [==============================] - 210s 441ms/step - loss: 0.6127 - f1_m: 0.7744 - val_loss: 0.9255 - val_f1_m: 0.7119\n",
      "Epoch 6/70\n",
      "476/476 [==============================] - 211s 443ms/step - loss: 0.4759 - f1_m: 0.8385 - val_loss: 1.0130 - val_f1_m: 0.6906\n",
      "Epoch 7/70\n",
      "476/476 [==============================] - 210s 441ms/step - loss: 0.3775 - f1_m: 0.8719 - val_loss: 0.9943 - val_f1_m: 0.7103\n",
      "Epoch 8/70\n",
      "476/476 [==============================] - 210s 442ms/step - loss: 0.3164 - f1_m: 0.8882 - val_loss: 1.1315 - val_f1_m: 0.7014\n",
      "Epoch 9/70\n",
      "476/476 [==============================] - 211s 442ms/step - loss: 0.2400 - f1_m: 0.9203 - val_loss: 1.1328 - val_f1_m: 0.7166\n",
      "Epoch 10/70\n",
      "476/476 [==============================] - 210s 440ms/step - loss: 0.1913 - f1_m: 0.9426 - val_loss: 1.2652 - val_f1_m: 0.6775\n",
      "Epoch 11/70\n",
      "476/476 [==============================] - 210s 441ms/step - loss: 0.1727 - f1_m: 0.9474 - val_loss: 1.2335 - val_f1_m: 0.7185\n",
      "Epoch 12/70\n",
      "476/476 [==============================] - 210s 442ms/step - loss: 0.1540 - f1_m: 0.9507 - val_loss: 1.2187 - val_f1_m: 0.7300\n",
      "Epoch 13/70\n",
      "476/476 [==============================] - 210s 442ms/step - loss: 0.1361 - f1_m: 0.9588 - val_loss: 1.2739 - val_f1_m: 0.7178\n",
      "Epoch 14/70\n",
      "476/476 [==============================] - 210s 441ms/step - loss: 0.1245 - f1_m: 0.9598 - val_loss: 1.2687 - val_f1_m: 0.7262\n",
      "Epoch 15/70\n",
      "476/476 [==============================] - 210s 442ms/step - loss: 0.1178 - f1_m: 0.9658 - val_loss: 1.3930 - val_f1_m: 0.6868\n",
      "Epoch 16/70\n",
      "476/476 [==============================] - 211s 442ms/step - loss: 0.0969 - f1_m: 0.9688 - val_loss: 1.3204 - val_f1_m: 0.7093\n",
      "Epoch 17/70\n",
      "476/476 [==============================] - 211s 442ms/step - loss: 0.1322 - f1_m: 0.9598 - val_loss: 1.3773 - val_f1_m: 0.7107\n",
      "Epoch 18/70\n",
      "476/476 [==============================] - 210s 441ms/step - loss: 0.0887 - f1_m: 0.9699 - val_loss: 1.3397 - val_f1_m: 0.7078\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00018: early stopping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3804 validated image filenames belonging to 15 classes.\n",
      "Found 544 validated image filenames belonging to 15 classes.\n",
      "Epoch 1/70\n",
      "476/476 [==============================] - 223s 446ms/step - loss: 1.9927 - f1_m: 0.2116 - val_loss: 1.2390 - val_f1_m: 0.5097\n",
      "Epoch 2/70\n",
      "476/476 [==============================] - 209s 439ms/step - loss: 1.1394 - f1_m: 0.6016 - val_loss: 1.1123 - val_f1_m: 0.5964\n",
      "Epoch 3/70\n",
      "476/476 [==============================] - 209s 439ms/step - loss: 0.8601 - f1_m: 0.6976 - val_loss: 1.0035 - val_f1_m: 0.6678\n",
      "Epoch 4/70\n",
      "476/476 [==============================] - 210s 440ms/step - loss: 0.7283 - f1_m: 0.7462 - val_loss: 1.0033 - val_f1_m: 0.6772\n",
      "Epoch 5/70\n",
      "476/476 [==============================] - 210s 440ms/step - loss: 0.5715 - f1_m: 0.8093 - val_loss: 1.0256 - val_f1_m: 0.6942\n",
      "Epoch 6/70\n",
      "476/476 [==============================] - 210s 441ms/step - loss: 0.4515 - f1_m: 0.8471 - val_loss: 1.0786 - val_f1_m: 0.6898\n",
      "Epoch 7/70\n",
      "476/476 [==============================] - 209s 440ms/step - loss: 0.3795 - f1_m: 0.8786 - val_loss: 1.0842 - val_f1_m: 0.6848\n",
      "Epoch 8/70\n",
      "476/476 [==============================] - 209s 439ms/step - loss: 0.3005 - f1_m: 0.9041 - val_loss: 1.1665 - val_f1_m: 0.7011\n",
      "Epoch 9/70\n",
      "476/476 [==============================] - 209s 439ms/step - loss: 0.2405 - f1_m: 0.9194 - val_loss: 1.2405 - val_f1_m: 0.6623\n",
      "Epoch 10/70\n",
      "476/476 [==============================] - 211s 443ms/step - loss: 0.1963 - f1_m: 0.9390 - val_loss: 1.3139 - val_f1_m: 0.6903\n",
      "Epoch 11/70\n",
      "476/476 [==============================] - 210s 440ms/step - loss: 0.1943 - f1_m: 0.9333 - val_loss: 1.3793 - val_f1_m: 0.7038\n",
      "Epoch 12/70\n",
      "476/476 [==============================] - 209s 439ms/step - loss: 0.1872 - f1_m: 0.9348 - val_loss: 1.5095 - val_f1_m: 0.6662\n",
      "Epoch 13/70\n",
      "476/476 [==============================] - 210s 440ms/step - loss: 0.1622 - f1_m: 0.9512 - val_loss: 1.5305 - val_f1_m: 0.6909\n",
      "Epoch 14/70\n",
      "476/476 [==============================] - 209s 440ms/step - loss: 0.1326 - f1_m: 0.9580 - val_loss: 1.4693 - val_f1_m: 0.6934\n",
      "Epoch 15/70\n",
      "476/476 [==============================] - 209s 440ms/step - loss: 0.1143 - f1_m: 0.9614 - val_loss: 1.5297 - val_f1_m: 0.6844\n",
      "Epoch 16/70\n",
      "476/476 [==============================] - 209s 440ms/step - loss: 0.0958 - f1_m: 0.9662 - val_loss: 1.5399 - val_f1_m: 0.7013\n",
      "Epoch 17/70\n",
      "476/476 [==============================] - 209s 438ms/step - loss: 0.1035 - f1_m: 0.9671 - val_loss: 1.5663 - val_f1_m: 0.6748\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00017: early stopping\n",
      "Found 3805 validated image filenames belonging to 15 classes.\n",
      "Found 543 validated image filenames belonging to 15 classes.\n",
      "Epoch 1/70\n",
      "476/476 [==============================] - 224s 450ms/step - loss: 2.0171 - f1_m: 0.2057 - val_loss: 1.1953 - val_f1_m: 0.5564\n",
      "Epoch 2/70\n",
      "476/476 [==============================] - 211s 442ms/step - loss: 1.1791 - f1_m: 0.5757 - val_loss: 1.0183 - val_f1_m: 0.6550\n",
      "Epoch 3/70\n",
      "476/476 [==============================] - 211s 442ms/step - loss: 0.9275 - f1_m: 0.6772 - val_loss: 0.9396 - val_f1_m: 0.6834\n",
      "Epoch 4/70\n",
      "476/476 [==============================] - 210s 441ms/step - loss: 0.7520 - f1_m: 0.7338 - val_loss: 0.9172 - val_f1_m: 0.6832\n",
      "Epoch 5/70\n",
      "476/476 [==============================] - 210s 440ms/step - loss: 0.6006 - f1_m: 0.7955 - val_loss: 0.9153 - val_f1_m: 0.7084\n",
      "Epoch 6/70\n",
      "476/476 [==============================] - 209s 439ms/step - loss: 0.5175 - f1_m: 0.8242 - val_loss: 0.9640 - val_f1_m: 0.7169\n",
      "Epoch 7/70\n",
      "476/476 [==============================] - 210s 440ms/step - loss: 0.3880 - f1_m: 0.8678 - val_loss: 0.9838 - val_f1_m: 0.7180\n",
      "Epoch 8/70\n",
      "476/476 [==============================] - 211s 442ms/step - loss: 0.3168 - f1_m: 0.8977 - val_loss: 1.0456 - val_f1_m: 0.7217\n",
      "Epoch 9/70\n",
      "476/476 [==============================] - 210s 442ms/step - loss: 0.2745 - f1_m: 0.9120 - val_loss: 1.0150 - val_f1_m: 0.7285\n",
      "Epoch 10/70\n",
      "476/476 [==============================] - 210s 441ms/step - loss: 0.2122 - f1_m: 0.9367 - val_loss: 1.1400 - val_f1_m: 0.7164\n",
      "Epoch 11/70\n",
      "476/476 [==============================] - 211s 443ms/step - loss: 0.2000 - f1_m: 0.9324 - val_loss: 1.2423 - val_f1_m: 0.7211\n",
      "Epoch 12/70\n",
      "476/476 [==============================] - 210s 440ms/step - loss: 0.1611 - f1_m: 0.9439 - val_loss: 1.2257 - val_f1_m: 0.7365\n",
      "Epoch 13/70\n",
      "476/476 [==============================] - 210s 440ms/step - loss: 0.1475 - f1_m: 0.9467 - val_loss: 1.3694 - val_f1_m: 0.7243\n",
      "Epoch 14/70\n",
      "476/476 [==============================] - 210s 442ms/step - loss: 0.1421 - f1_m: 0.9532 - val_loss: 1.3205 - val_f1_m: 0.7322\n",
      "Epoch 15/70\n",
      "476/476 [==============================] - 211s 442ms/step - loss: 0.1248 - f1_m: 0.9640 - val_loss: 1.3154 - val_f1_m: 0.7256\n",
      "Epoch 16/70\n",
      "476/476 [==============================] - 210s 441ms/step - loss: 0.1087 - f1_m: 0.9652 - val_loss: 1.3528 - val_f1_m: 0.7400\n",
      "Epoch 17/70\n",
      "476/476 [==============================] - 210s 441ms/step - loss: 0.1007 - f1_m: 0.9692 - val_loss: 1.3536 - val_f1_m: 0.7364\n",
      "Epoch 18/70\n",
      "476/476 [==============================] - 211s 442ms/step - loss: 0.0790 - f1_m: 0.9758 - val_loss: 1.4699 - val_f1_m: 0.7347\n",
      "Epoch 19/70\n",
      "476/476 [==============================] - 210s 442ms/step - loss: 0.0984 - f1_m: 0.9653 - val_loss: 1.4253 - val_f1_m: 0.7271\n",
      "Epoch 20/70\n",
      "476/476 [==============================] - 210s 441ms/step - loss: 0.0783 - f1_m: 0.9753 - val_loss: 1.5312 - val_f1_m: 0.7070\n",
      "Epoch 21/70\n",
      "476/476 [==============================] - 210s 441ms/step - loss: 0.0798 - f1_m: 0.9739 - val_loss: 1.6357 - val_f1_m: 0.7166\n",
      "Epoch 22/70\n",
      "476/476 [==============================] - 211s 444ms/step - loss: 0.0690 - f1_m: 0.9767 - val_loss: 1.6193 - val_f1_m: 0.7379\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00022: early stopping\n",
      "Found 3805 validated image filenames belonging to 15 classes.\n",
      "Found 543 validated image filenames belonging to 15 classes.\n",
      "Epoch 1/70\n",
      "476/476 [==============================] - 223s 447ms/step - loss: 2.0277 - f1_m: 0.1971 - val_loss: 1.2171 - val_f1_m: 0.5623\n",
      "Epoch 2/70\n",
      "476/476 [==============================] - 210s 441ms/step - loss: 1.1180 - f1_m: 0.6068 - val_loss: 1.0356 - val_f1_m: 0.6527\n",
      "Epoch 3/70\n",
      "476/476 [==============================] - 210s 442ms/step - loss: 0.9098 - f1_m: 0.6873 - val_loss: 0.9933 - val_f1_m: 0.6770\n",
      "Epoch 4/70\n",
      "476/476 [==============================] - 210s 440ms/step - loss: 0.7433 - f1_m: 0.7428 - val_loss: 1.0121 - val_f1_m: 0.7047\n",
      "Epoch 5/70\n",
      "476/476 [==============================] - 210s 440ms/step - loss: 0.5672 - f1_m: 0.8032 - val_loss: 1.0157 - val_f1_m: 0.6991\n",
      "Epoch 6/70\n",
      "476/476 [==============================] - 211s 444ms/step - loss: 0.4811 - f1_m: 0.8330 - val_loss: 1.0812 - val_f1_m: 0.6953\n",
      "Epoch 7/70\n",
      "476/476 [==============================] - 210s 442ms/step - loss: 0.3766 - f1_m: 0.8762 - val_loss: 1.0963 - val_f1_m: 0.7153\n",
      "Epoch 8/70\n",
      "476/476 [==============================] - 210s 442ms/step - loss: 0.3076 - f1_m: 0.9016 - val_loss: 1.1977 - val_f1_m: 0.6953\n",
      "Epoch 9/70\n",
      "476/476 [==============================] - 210s 441ms/step - loss: 0.2490 - f1_m: 0.9165 - val_loss: 1.2574 - val_f1_m: 0.7038\n",
      "Epoch 10/70\n",
      "476/476 [==============================] - 214s 450ms/step - loss: 0.2022 - f1_m: 0.9335 - val_loss: 1.3002 - val_f1_m: 0.7318\n",
      "Epoch 11/70\n",
      "476/476 [==============================] - 210s 440ms/step - loss: 0.1771 - f1_m: 0.9470 - val_loss: 1.3508 - val_f1_m: 0.6897\n",
      "Epoch 12/70\n",
      "476/476 [==============================] - 209s 438ms/step - loss: 0.1314 - f1_m: 0.9554 - val_loss: 1.3519 - val_f1_m: 0.7257\n",
      "Epoch 13/70\n",
      "476/476 [==============================] - 209s 440ms/step - loss: 0.1401 - f1_m: 0.9568 - val_loss: 1.4454 - val_f1_m: 0.7141\n",
      "Epoch 14/70\n",
      "476/476 [==============================] - 209s 438ms/step - loss: 0.1115 - f1_m: 0.9615 - val_loss: 1.4438 - val_f1_m: 0.7002\n",
      "Epoch 15/70\n",
      "476/476 [==============================] - 210s 440ms/step - loss: 0.1025 - f1_m: 0.9671 - val_loss: 1.5705 - val_f1_m: 0.7165\n",
      "Epoch 16/70\n",
      "476/476 [==============================] - 209s 438ms/step - loss: 0.1067 - f1_m: 0.9669 - val_loss: 1.5995 - val_f1_m: 0.7080\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3805 validated image filenames belonging to 15 classes.\n",
      "Found 543 validated image filenames belonging to 15 classes.\n",
      "Epoch 1/70\n",
      "476/476 [==============================] - 221s 442ms/step - loss: 2.0168 - f1_m: 0.2162 - val_loss: 1.2693 - val_f1_m: 0.5361\n",
      "Epoch 2/70\n",
      "476/476 [==============================] - 209s 439ms/step - loss: 1.1725 - f1_m: 0.5775 - val_loss: 1.0257 - val_f1_m: 0.6475\n",
      "Epoch 3/70\n",
      "476/476 [==============================] - 209s 438ms/step - loss: 0.8778 - f1_m: 0.6919 - val_loss: 0.9390 - val_f1_m: 0.6760\n",
      "Epoch 4/70\n",
      "476/476 [==============================] - 209s 438ms/step - loss: 0.7446 - f1_m: 0.7314 - val_loss: 0.9217 - val_f1_m: 0.7159\n",
      "Epoch 5/70\n",
      "476/476 [==============================] - 209s 438ms/step - loss: 0.5934 - f1_m: 0.7914 - val_loss: 0.9845 - val_f1_m: 0.7002\n",
      "Epoch 6/70\n",
      "476/476 [==============================] - 209s 439ms/step - loss: 0.4484 - f1_m: 0.8408 - val_loss: 0.9915 - val_f1_m: 0.7091\n",
      "Epoch 7/70\n",
      "476/476 [==============================] - 209s 439ms/step - loss: 0.3842 - f1_m: 0.8703 - val_loss: 1.0962 - val_f1_m: 0.6999\n",
      "Epoch 8/70\n",
      "476/476 [==============================] - 210s 442ms/step - loss: 0.3219 - f1_m: 0.8919 - val_loss: 1.0872 - val_f1_m: 0.7332\n",
      "Epoch 9/70\n",
      "476/476 [==============================] - 215s 451ms/step - loss: 0.2493 - f1_m: 0.9187 - val_loss: 1.1468 - val_f1_m: 0.7311\n",
      "Epoch 10/70\n",
      "476/476 [==============================] - 209s 438ms/step - loss: 0.2157 - f1_m: 0.9278 - val_loss: 1.1943 - val_f1_m: 0.7150\n",
      "Epoch 11/70\n",
      "476/476 [==============================] - 209s 440ms/step - loss: 0.1810 - f1_m: 0.9421 - val_loss: 1.2283 - val_f1_m: 0.7378\n",
      "Epoch 12/70\n",
      "476/476 [==============================] - 209s 438ms/step - loss: 0.1501 - f1_m: 0.9510 - val_loss: 1.2662 - val_f1_m: 0.7226\n",
      "Epoch 13/70\n",
      "476/476 [==============================] - 208s 438ms/step - loss: 0.1383 - f1_m: 0.9549 - val_loss: 1.2224 - val_f1_m: 0.7404\n",
      "Epoch 14/70\n",
      "476/476 [==============================] - 212s 446ms/step - loss: 0.1105 - f1_m: 0.9649 - val_loss: 1.4174 - val_f1_m: 0.7225\n",
      "Epoch 15/70\n",
      "476/476 [==============================] - 210s 440ms/step - loss: 0.1116 - f1_m: 0.9645 - val_loss: 1.4444 - val_f1_m: 0.7247\n",
      "Epoch 16/70\n",
      "476/476 [==============================] - 211s 442ms/step - loss: 0.1104 - f1_m: 0.9633 - val_loss: 1.4699 - val_f1_m: 0.7218\n",
      "Epoch 17/70\n",
      "476/476 [==============================] - 210s 440ms/step - loss: 0.0818 - f1_m: 0.9700 - val_loss: 1.4885 - val_f1_m: 0.7273\n",
      "Epoch 18/70\n",
      "476/476 [==============================] - 210s 442ms/step - loss: 0.0947 - f1_m: 0.9694 - val_loss: 1.5855 - val_f1_m: 0.7292\n",
      "Epoch 19/70\n",
      "476/476 [==============================] - 211s 444ms/step - loss: 0.0830 - f1_m: 0.9729 - val_loss: 1.6165 - val_f1_m: 0.6972\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00019: early stopping\n",
      "Found 3805 validated image filenames belonging to 15 classes.\n",
      "Found 543 validated image filenames belonging to 15 classes.\n",
      "Epoch 1/70\n",
      "476/476 [==============================] - 224s 443ms/step - loss: 2.0234 - f1_m: 0.1981 - val_loss: 1.2084 - val_f1_m: 0.5707\n",
      "Epoch 2/70\n",
      "476/476 [==============================] - 209s 438ms/step - loss: 1.1415 - f1_m: 0.5969 - val_loss: 0.9904 - val_f1_m: 0.6663\n",
      "Epoch 3/70\n",
      "476/476 [==============================] - 209s 439ms/step - loss: 0.8968 - f1_m: 0.6848 - val_loss: 0.9069 - val_f1_m: 0.7021\n",
      "Epoch 4/70\n",
      "476/476 [==============================] - 213s 446ms/step - loss: 0.7144 - f1_m: 0.7512 - val_loss: 0.9144 - val_f1_m: 0.7074\n",
      "Epoch 5/70\n",
      "476/476 [==============================] - 211s 443ms/step - loss: 0.5970 - f1_m: 0.8056 - val_loss: 0.9773 - val_f1_m: 0.6869\n",
      "Epoch 6/70\n",
      "476/476 [==============================] - 219s 459ms/step - loss: 0.4707 - f1_m: 0.8427 - val_loss: 1.0126 - val_f1_m: 0.6995\n",
      "Epoch 7/70\n",
      "476/476 [==============================] - 224s 469ms/step - loss: 0.3795 - f1_m: 0.8661 - val_loss: 1.1157 - val_f1_m: 0.6753\n",
      "Epoch 8/70\n",
      "476/476 [==============================] - 223s 469ms/step - loss: 0.2966 - f1_m: 0.8983 - val_loss: 1.0395 - val_f1_m: 0.7231\n",
      "Epoch 9/70\n",
      "476/476 [==============================] - 226s 475ms/step - loss: 0.2240 - f1_m: 0.9305 - val_loss: 1.1145 - val_f1_m: 0.6887\n",
      "Epoch 10/70\n",
      "476/476 [==============================] - 227s 478ms/step - loss: 0.2051 - f1_m: 0.9311 - val_loss: 1.1900 - val_f1_m: 0.7008\n",
      "Epoch 11/70\n",
      "476/476 [==============================] - 226s 475ms/step - loss: 0.1728 - f1_m: 0.9454 - val_loss: 1.2114 - val_f1_m: 0.7102\n",
      "Epoch 12/70\n",
      "476/476 [==============================] - 227s 477ms/step - loss: 0.1636 - f1_m: 0.9483 - val_loss: 1.1481 - val_f1_m: 0.7191\n",
      "Epoch 13/70\n",
      "476/476 [==============================] - 227s 478ms/step - loss: 0.1475 - f1_m: 0.9490 - val_loss: 1.3029 - val_f1_m: 0.7216\n",
      "Epoch 14/70\n",
      "476/476 [==============================] - 226s 473ms/step - loss: 0.1125 - f1_m: 0.9657 - val_loss: 1.2945 - val_f1_m: 0.7364\n",
      "Epoch 15/70\n",
      "476/476 [==============================] - 218s 457ms/step - loss: 0.1098 - f1_m: 0.9635 - val_loss: 1.4025 - val_f1_m: 0.7070\n",
      "Epoch 16/70\n",
      "476/476 [==============================] - 208s 437ms/step - loss: 0.0993 - f1_m: 0.9694 - val_loss: 1.4180 - val_f1_m: 0.7087\n",
      "Epoch 17/70\n",
      "476/476 [==============================] - 212s 445ms/step - loss: 0.0905 - f1_m: 0.9730 - val_loss: 1.3712 - val_f1_m: 0.7205\n",
      "Epoch 18/70\n",
      "476/476 [==============================] - 214s 450ms/step - loss: 0.0775 - f1_m: 0.9777 - val_loss: 1.5345 - val_f1_m: 0.7025\n",
      "Epoch 19/70\n",
      "476/476 [==============================] - 208s 438ms/step - loss: 0.0806 - f1_m: 0.9761 - val_loss: 1.3577 - val_f1_m: 0.7334\n",
      "Epoch 20/70\n",
      "476/476 [==============================] - 208s 438ms/step - loss: 0.0870 - f1_m: 0.9721 - val_loss: 1.4697 - val_f1_m: 0.7417\n",
      "Epoch 21/70\n",
      "476/476 [==============================] - ETA: 0s - loss: 0.0764 - f1_m: 0.9753"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "es = EarlyStopping(monitor='val_f1_m', patience=6, restore_best_weights=True, verbose=1, mode='max')\n",
    "skf = StratifiedKFold(n_splits=8, shuffle=True, random_state=seed)\n",
    "for fold, (idxT, idxV) in enumerate(skf.split(train, train['typology'])):\n",
    "    train_generator = create_datagen(train.iloc[idxT])\n",
    "    valid_generator = create_datagen(train.iloc[idxV])\n",
    "    model_label, model_bn = architecture_NN()\n",
    "    model_label.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(LR), metrics=[f1_m])\n",
    "    history = model_label.fit(train_generator, \n",
    "                        validation_data=valid_generator,\n",
    "                        callbacks=[es],\n",
    "                        epochs = num_epochs)\n",
    "    model_label.save(f\"Model_img/model_predict_with_bottle_neck_{fold}.h5\")\n",
    "    model_bn.save(f\"model_img/model_bottle_neck_{fold}.h5\")\n",
    "print(f\"hours: {(time.time()-start_time)/3600}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
